{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e06f6d-cdca-4bc8-996d-e1a7953b1b01",
   "metadata": {},
   "source": [
    "- Name: Deep Salunkhe\n",
    "- Roll No.:21102A0014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efbf44a6-3fe0-445f-941d-70c5bf9f4984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hmmlearnNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading hmmlearn-0.3.2-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: numpy>=1.10 in d:\\anaconda\\lib\\site-packages (from hmmlearn) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in d:\\anaconda\\lib\\site-packages (from hmmlearn) (1.2.2)\n",
      "Requirement already satisfied: scipy>=0.19 in d:\\anaconda\\lib\\site-packages (from hmmlearn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\anaconda\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (2.2.0)\n",
      "Downloading hmmlearn-0.3.2-cp311-cp311-win_amd64.whl (125 kB)\n",
      "   ---------------------------------------- 0.0/125.4 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/125.4 kB ? eta -:--:--\n",
      "   --------------------------------------  122.9/125.4 kB 1.8 MB/s eta 0:00:01\n",
      "   --------------------------------------- 125.4/125.4 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: hmmlearn\n",
      "Successfully installed hmmlearn-0.3.2\n"
     ]
    }
   ],
   "source": [
    "pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68e7f1d2-946b-4b73-86d1-1166fc828f88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix:\n",
      "{'NNP': {'NNP': 0, 'VBG': 0, 'VBZ': 1, 'NN': 0, 'IN': 0, 'DT': 0}, 'VBG': {'NNP': 0, 'VBG': 0, 'VBZ': 0, 'NN': 0, 'IN': 1, 'DT': 0}, 'VBZ': {'NNP': 0, 'VBG': 1, 'VBZ': 0, 'NN': 0, 'IN': 0, 'DT': 0}, 'NN': {'NNP': 0, 'VBG': 0, 'VBZ': 0, 'NN': 0, 'IN': 1, 'DT': 0}, 'IN': {'NNP': 0, 'VBG': 0, 'VBZ': 0, 'NN': 0, 'IN': 0, 'DT': 2}, 'DT': {'NNP': 0, 'VBG': 0, 'VBZ': 0, 'NN': 2, 'IN': 0, 'DT': 0}}\n",
      "\n",
      "Emission Matrix:\n",
      "{'NNP': {'Ram': 1, 'is': 0, 'standing': 0, 'on': 0, 'the': 0, 'bank': 0, 'of': 0, 'river': 0}, 'VBG': {'Ram': 0, 'is': 0, 'standing': 1, 'on': 0, 'the': 0, 'bank': 0, 'of': 0, 'river': 0}, 'VBZ': {'Ram': 0, 'is': 1, 'standing': 0, 'on': 0, 'the': 0, 'bank': 0, 'of': 0, 'river': 0}, 'NN': {'Ram': 0, 'is': 0, 'standing': 0, 'on': 0, 'the': 0, 'bank': 1, 'of': 0, 'river': 1}, 'IN': {'Ram': 0, 'is': 0, 'standing': 0, 'on': 1, 'the': 0, 'bank': 0, 'of': 1, 'river': 0}, 'DT': {'Ram': 0, 'is': 0, 'standing': 0, 'on': 0, 'the': 2, 'bank': 0, 'of': 0, 'river': 0}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Deep\n",
      "[nltk_data]     Salunkhe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Deep Salunkhe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def calculate_matrices(sentence):\n",
    "    # Tokenize and tag the sentence\n",
    "    tokens = nltk.word_tokenize(sentence)\n",
    "    tagged_sentence = pos_tag(tokens)\n",
    "    \n",
    "    # Calculate transition matrix\n",
    "    transitions = FreqDist(((tag1, tag2) for ((word1, tag1), (word2, tag2)) in nltk.bigrams(tagged_sentence)))\n",
    "    unique_tags = set(tag for word, tag in tagged_sentence)\n",
    "    transition_matrix = {tag1: {tag2: transitions[(tag1, tag2)] for tag2 in unique_tags} for tag1 in unique_tags}\n",
    "    \n",
    "    # Calculate emission matrix\n",
    "    emissions = FreqDist((tag, word) for word, tag in tagged_sentence)\n",
    "    emission_matrix = {tag: {word: emissions[(tag, word)] for word, _ in tagged_sentence} for tag in unique_tags}\n",
    "    \n",
    "    return transition_matrix, emission_matrix\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Ram is standing on the bank of the river\"\n",
    "transition_matrix, emission_matrix = calculate_matrices(sentence)\n",
    "\n",
    "print(\"Transition Matrix:\")\n",
    "print(transition_matrix)\n",
    "print(\"\\nEmission Matrix:\")\n",
    "print(emission_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10396b6a-d829-4725-87b2-6da973cd8329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transition Matrix:\n",
      "{'NNP': {'VBZ': 1}, 'VBZ': {'VBG': 1}, 'VBG': {'IN': 1}, 'IN': {'DT': 2}, 'DT': {'NN': 2}, 'NN': {'IN': 1}}\n",
      "\n",
      "Emission Matrix:\n",
      "{'NNP': {'Ram': 1}, 'VBZ': {'is': 1}, 'VBG': {'standing': 1}, 'IN': {'on': 1, 'of': 1}, 'DT': {'the': 2}, 'NN': {'bank': 1, 'river': 1}}\n"
     ]
    }
   ],
   "source": [
    "def calculate_matrices_hardcoded(sentence, pos_tags):\n",
    "    words = sentence.split()\n",
    "    \n",
    "    # Calculate transition matrix\n",
    "    transition_matrix = {}\n",
    "    for i in range(len(pos_tags) - 1):\n",
    "        if pos_tags[i] not in transition_matrix:\n",
    "            transition_matrix[pos_tags[i]] = {}\n",
    "        if pos_tags[i+1] not in transition_matrix[pos_tags[i]]:\n",
    "            transition_matrix[pos_tags[i]][pos_tags[i+1]] = 0\n",
    "        transition_matrix[pos_tags[i]][pos_tags[i+1]] += 1\n",
    "    \n",
    "    # Calculate emission matrix\n",
    "    emission_matrix = {}\n",
    "    for i, tag in enumerate(pos_tags):\n",
    "        if tag not in emission_matrix:\n",
    "            emission_matrix[tag] = {}\n",
    "        if words[i] not in emission_matrix[tag]:\n",
    "            emission_matrix[tag][words[i]] = 0\n",
    "        emission_matrix[tag][words[i]] += 1\n",
    "    \n",
    "    return transition_matrix, emission_matrix\n",
    "\n",
    "# Example usage\n",
    "sentence = \"Ram is standing on the bank of the river\"\n",
    "pos_tags = [\"NNP\", \"VBZ\", \"VBG\", \"IN\", \"DT\", \"NN\", \"IN\", \"DT\", \"NN\"]\n",
    "\n",
    "transition_matrix, emission_matrix = calculate_matrices_hardcoded(sentence, pos_tags)\n",
    "\n",
    "print(\"Transition Matrix:\")\n",
    "print(transition_matrix)\n",
    "print(\"\\nEmission Matrix:\")\n",
    "print(emission_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362a3524-e20c-4704-8187-6749e05fa0ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
