{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebe37852-6db8-4cd3-a175-902d8ded088f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
      "0    -122.23     37.88                41.0        880.0           129.0   \n",
      "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
      "2    -122.24     37.85                52.0       1467.0           190.0   \n",
      "3    -122.25     37.85                52.0       1274.0           235.0   \n",
      "4    -122.25     37.85                52.0       1627.0           280.0   \n",
      "\n",
      "   population  households  median_income  median_house_value ocean_proximity  \n",
      "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
      "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
      "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
      "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
      "4       565.0       259.0         3.8462            342200.0        NEAR BAY  \n",
      "Mean Absolute Error: 50670.73824097189\n",
      "Mean Squared Error: 4908476721.156615\n",
      "R-squared: 0.6254240620553606\n",
      "Model saved successfully!\n",
      "Mean Absolute Error (Loaded Model): 50670.73824097189\n",
      "Mean Squared Error (Loaded Model): 4908476721.156615\n",
      "R-squared (Loaded Model): 0.6254240620553606\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import joblib\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('housing.csv')\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "print(df.head())\n",
    "\n",
    "# Handle missing values\n",
    "df['total_bedrooms'].fillna(df['total_bedrooms'].median(), inplace=True)\n",
    "\n",
    "# Identify categorical columns (assuming 'ocean_proximity' is a categorical column in the dataset)\n",
    "categorical_columns = ['ocean_proximity']\n",
    "numerical_columns = df.columns.drop(categorical_columns + ['median_house_value'])\n",
    "\n",
    "# Create a column transformer to apply transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Apply transformations to the dataframe\n",
    "df_preprocessed = preprocessor.fit_transform(df)\n",
    "\n",
    "# Convert to DataFrame for better handling\n",
    "df_scaled = pd.DataFrame(df_preprocessed, columns=numerical_columns.tolist() + preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns).tolist())\n",
    "\n",
    "# Separate features and target\n",
    "X = df_scaled\n",
    "y = df['median_house_value']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'housing_price_model.pkl')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('housing_price_model.pkl')\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "y_pred_loaded = loaded_model.predict(X_test)\n",
    "\n",
    "# Evaluate the loaded model\n",
    "mae_loaded = mean_absolute_error(y_test, y_pred_loaded)\n",
    "mse_loaded = mean_squared_error(y_test, y_pred_loaded)\n",
    "r2_loaded = r2_score(y_test, y_pred_loaded)\n",
    "\n",
    "print(f'Mean Absolute Error (Loaded Model): {mae_loaded}')\n",
    "print(f'Mean Squared Error (Loaded Model): {mse_loaded}')\n",
    "print(f'R-squared (Loaded Model): {r2_loaded}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b95b1a46-3d70-4e3f-8df5-26b1a15e2ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter longitude:  -122.23\n",
      "Enter latitude:  37.88\n",
      "Enter housing_median_age:  41\n",
      "Enter total_rooms:  880\n",
      "Enter total_bedrooms:  129\n",
      "Enter population:  322\n",
      "Enter households:  126\n",
      "Enter median_income:  8.3252\n",
      "Enter ocean_proximity (e.g., NEAR BAY, INLAND, etc.):  NEAR BAY\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Median House Value: $410584.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\base.py:439: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('housing.csv')\n",
    "\n",
    "# Handle missing values\n",
    "df['total_bedrooms'].fillna(df['total_bedrooms'].median(), inplace=True)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = ['ocean_proximity']\n",
    "numerical_columns = df.columns.drop(categorical_columns + ['median_house_value'])\n",
    "\n",
    "# Create a column transformer to apply transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Apply transformations to the dataframe\n",
    "df_preprocessed = preprocessor.fit_transform(df)\n",
    "\n",
    "# Convert to DataFrame for better handling\n",
    "df_scaled = pd.DataFrame(df_preprocessed, columns=numerical_columns.tolist() + preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns).tolist())\n",
    "\n",
    "# Separate features and target\n",
    "X = df_scaled\n",
    "y = df['median_house_value']\n",
    "\n",
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'housing_price_model.pkl')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('housing_price_model.pkl')\n",
    "\n",
    "# Function to preprocess and predict user input\n",
    "def preprocess_and_predict(user_input):\n",
    "    # Convert user input to DataFrame\n",
    "    user_df = pd.DataFrame([user_input], columns=numerical_columns.tolist() + categorical_columns)\n",
    "    \n",
    "    # Handle categorical data (one-hot encoding)\n",
    "    user_preprocessed = preprocessor.transform(user_df)\n",
    "    \n",
    "    # Make predictions\n",
    "    prediction = loaded_model.predict(user_preprocessed)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Take user input\n",
    "user_input = {}\n",
    "for column in numerical_columns:\n",
    "    user_input[column] = float(input(f\"Enter {column}: \"))\n",
    "\n",
    "for column in categorical_columns:\n",
    "    user_input[column] = input(f\"Enter {column} (e.g., NEAR BAY, INLAND, etc.): \")\n",
    "\n",
    "# Predict based on user input\n",
    "prediction = preprocess_and_predict(user_input)\n",
    "print(f\"Predicted Median House Value: ${prediction[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce682aa2-001e-49ad-8723-43a5085ce887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter longitude:  -122.23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('housing.csv')\n",
    "\n",
    "# Handle missing values\n",
    "df['total_bedrooms'].fillna(df['total_bedrooms'].median(), inplace=True)\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_columns = ['ocean_proximity']\n",
    "numerical_columns = df.columns.drop(categorical_columns + ['median_house_value'])\n",
    "\n",
    "# Create a column transformer to apply transformations\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_columns),\n",
    "        ('cat', OneHotEncoder(), categorical_columns)\n",
    "    ])\n",
    "\n",
    "# Apply transformations to the dataframe\n",
    "df_preprocessed = preprocessor.fit_transform(df)\n",
    "\n",
    "# Convert to DataFrame for better handling\n",
    "feature_names = numerical_columns.tolist() + preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns).tolist()\n",
    "df_scaled = pd.DataFrame(df_preprocessed, columns=feature_names)\n",
    "\n",
    "# Separate features and target\n",
    "X = df_scaled\n",
    "y = df['median_house_value']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, 'housing_price_model.pkl')\n",
    "print(\"Model saved successfully!\")\n",
    "\n",
    "# Load the model\n",
    "loaded_model = joblib.load('housing_price_model.pkl')\n",
    "\n",
    "# Function to preprocess and predict user input\n",
    "def preprocess_and_predict(user_input):\n",
    "    # Convert user input to DataFrame\n",
    "    user_df = pd.DataFrame([user_input], columns=numerical_columns.tolist() + categorical_columns)\n",
    "    \n",
    "    # Handle categorical data (one-hot encoding)\n",
    "    user_preprocessed = preprocessor.transform(user_df)\n",
    "    \n",
    "    # Convert to DataFrame with correct feature names\n",
    "    user_preprocessed_df = pd.DataFrame(user_preprocessed, columns=feature_names)\n",
    "    \n",
    "    # Make predictions\n",
    "    prediction = loaded_model.predict(user_preprocessed_df)\n",
    "    \n",
    "    return prediction\n",
    "\n",
    "# Take user input\n",
    "user_input = {}\n",
    "for column in numerical_columns:\n",
    "    user_input[column] = float(input(f\"Enter {column}: \"))\n",
    "\n",
    "for column in categorical_columns:\n",
    "    user_input[column] = input(f\"Enter {column} (e.g., NEAR BAY, INLAND, etc.): \")\n",
    "\n",
    "# Predict based on user input\n",
    "prediction = preprocess_and_predict(user_input)\n",
    "print(f\"Predicted Median House Value: ${prediction[0]:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adfcfd4-0e7c-4553-9cbe-90d807f4e59d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
